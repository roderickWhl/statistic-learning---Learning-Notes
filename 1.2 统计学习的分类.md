#### 1.2 统计学习的分类

##### 基本分类

1. **<font color='steelblue'>监督学习（supervised learning）</font>**<br>
   监督学习（supervised learning）是指从标注数据中学习预测模型的机器学习问题。标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。监督学习的本质是学习输入到输出的映射的统计规律。<br>

   - 输入空间(input space)、特征空间（feature  space）和输出空间（output space）：
     输入实例$x$的特征向量记作
       $$x=(x^{(1)},x^{(2)},...,x^{(i)},...,x^{(n)})^T$$
       $x^{(i)}$表示$x$的第$i$个特征。注意，$x_{(i)}$表示多个输入变量中的第$i$个变量，即
       $$x_i=(x_i^{(1)},x_i^{(2)},...,x_i^{(n)})^T$$
       监督学习从训练数据（training data）集合中学习模型，对测试数据（test data)进行预测。训练数据由输入（或特征向量）与输出对罪成，训练集通常表示为
       $$T=\lbrace(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\rbrace$$
       测试数据也由输入与输出对组成。输入与输出对又称为样本（sample）或样本点。
       输入变量$X$和输出变量$Y$有不同的类型，可以是连续的，也可以是离散的。输入变量与输出变量均为连续变量的预测问题称为回归问题；输出变量为有限个离散变量的预测问题称为分类问题；输入变量与输出变量均为变量序列的预测问题称为标注问题。

    - 联合概率分布：<br>
      监督学习假设输入与输出的随机变量X和Y遵循联合概率分布$P(X,Y)$。$P(X,Y)$表示分布函数，或分布密度函数。注意在学习过程中，假定这一联合概率分布存在，但对学习系统来说，联合概率分布的具体定义是未知的。训练数据与测试数据被看作是依联合概率分布$P(X,Y)$独立同分布产生的。统计学习假设数据存在一定的统计规律，X和Y具有联合概率分布就是监督学习关于数据的基本假设。

   - 假设空间：<br>
     监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。换句话说，学习的目的就在于找到这样最好的模型。模型属于由输入空间到输出空间的映射的集合，这个集合就是假设空间（hypothesis space）。假设空间的确定意味着学习的范围的确定。<br>
     监督学习的模型可以是概率模型或者非概率模型，由条件概率分布$P(Y|X)$或决策函数（decision function）$Y=f(X)$表示，随具体的学习方法而定。对具体的输入进行相应的输出预测时，写作$P(y|x)$或$y=f(x)$.

   - 问题的形式化：
     ![监督学习流程](https://roderickwhl.com/wp-content/uploads/2022/06/截屏2022-06-18-14.29.34.png)
     首先给定一个训练集
     $$T=\lbrace(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\rbrace$$
     其中$(x_i,y_i),i=1,2,...,N$，称为样本或样本点。$x_i\in\mathcal{X}\subseteq\mathbf{R}^n$，也称为输入或实例，$y\in\mathcal{Y}$是输出的预测值，也称为输出。

2. **<font color='steelblue'>无监督学习（unsupervised learning）</font>**<br>

   `无监督学习（unsupervised learning）`是指从`无标注数据`中学习预测模型的机器学习问题。无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率。无监督学习的本质是学习数据中的`统计规律`或`潜在结构`。

   模型的输入与输出的所有可能取值的集合分别为输入空间与输出空间。输入空间与输出空间可以是`有限元素集合`，也可以是`欧式空间`。每个输入是一个实例，由特征向量表示。每一个输出是对输入的`分析结果`，由输入的`类别`、`转换`或`概率`表示。模型可以实现对数据的`聚类`、`降维`或`概率估计`。

   假设$\mathcal{X}$是输入空间，$\mathcal{Z}$是隐式结构空间。要学习的模型可以表示为函数$z=g(x)$，条件概率分布$P(z|x)$，或者条件概率分布$P(x|z)$的形式，其中$x\in\mathcal{X}$是输入，$z\in\mathcal{Z}$是输出。包含所有可能的模型的集合称为`假设空间（hyperthethis space)`。无监督学习旨在从假设空间中选出在给定评价标准下的最优模型。

   无监督学习通常使用大量的***无标注数据***进行学习或训练，每一个样本是一个实例。训练数据表示为$U=\lbrace{x_1},{x_2},···,{x_N}\rbrace$，其中$x_i,i=1,2,···,N$，是样本。

   无监督学习可以用于对已有数据的分析，也可以用于对未来数据的预测。分析时使用学习得到的模型，即函数$z=\hat{g}(x)$或者概率分布$\hat{P}(x|z)$。在预测过程中，预测系统对于给定的输入$x_{N+1}$，由模型$z_{N+1}=\hat{g}(x_{N+1})$或$z_{N+1}=\mathop{\arg\max}_{z}\hat{P}(z|x_{N+1})$给出相应的输出$z_{N+1}$进行聚类或降维，或者由模型$\hat{P}(x|z)$给出输出的概率$\hat{P}(x_{N+1}|z_{N+1})$，进行概率估计。

   ![无监督学习](https://roderickwhl.com/wp-content/uploads/2022/06/截屏2022-06-19-10.36.20.png)

3. **<font color='steelblue'>强化学习（reinforcement learning）</font>**

   待更新

4. **<font color='steelblue'>半监督学习（semi-supervised learning）与主动学习（active learning）</font>**<br>

   待更新

##### 按模型分类

1. 概率模型与非概率模型
2. 线性模型与非线性模型
3. 参数化模型与非参数化模型

##### 按算法分类

1. 在线学习（online learning）
2. 批量学习（batch learning）

##### 按技巧分类

1. 贝叶斯学习（Bayesian learning），又称为贝叶斯推理（Bayesian inference）
2. 核方法（kernel method）